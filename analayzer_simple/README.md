# Sitemap.XML Analiz AracÄ±

## âš ï¸ YASAL UYARI

Bu araÃ§ **eÄŸitim amaÃ§lÄ±** olarak tasarlanmÄ±ÅŸtÄ±r. Kullanmadan Ã¶nce ÅŸunlarÄ± okumanÄ±z gerekir:

### âœ… YAPABILECEÄINIZ ÅEYLER:
- **Kendi web sitelerinizi** analiz etmek
- **AÃ§Ä±k test sitelerini** analiz etmek (izin verilmiÅŸ alanlar)
- **Åahsi laboratuvarÄ±nÄ±zÄ±** test etmek
- **Bug bounty programlarÄ±nda** katÄ±ldÄ±ÄŸÄ±nÄ±z siteleri test etmek (program kurallarÄ±na uygun ÅŸekilde)

### âŒ YAPAMAYACAÄINIZ ÅEYLER:
- Ä°zin **olmadan** baÅŸkasÄ±nÄ±n sitesini scrape etmek
- Trendyol, N11, Amazon, Instagram gibi **e-ticaret ve sosyal medya** sitelerini scrape etmek
- Banka, sigorta, finansal sitelerine eriÅŸim saÄŸlamak
- BaÅŸkasÄ±nÄ±n sunucusuna zarar vermek amacÄ±yla kullanmak

**Kural basit: Sadece izin verilen yerlerde kullanÄ±n!**

---

## ğŸ§ª TEST Ä°Ã§in YASAL SÄ°TELER

AÅŸaÄŸÄ±daki siteler scraping'e izin veriyor (robots.txt kontrolÃ¼ yapÄ±n):

### 1. **Wikipedia** âœ…
```bash
python sitemap_analyzer.py
# Domain: wikipedia.org
```
TÃ¼m sayfalarÄ± aÃ§Ä±kÃ§a listelemiÅŸtir.

### 2. **Quotes to Scrape** âœ…
```bash
python sitemap_analyzer.py
# Domain: quotes.toscrape.com
```
Scraping pratiÄŸi iÃ§in Ã¶zel olarak yapÄ±lmÄ±ÅŸ site.

### 3. **Books to Scrape** âœ…
```bash
python sitemap_analyzer.py
# Domain: books.toscrape.com
```
Kitap sitesi scraping Ã¶rneÄŸi.

### 4. **Example.com** âœ…
```bash
python sitemap_analyzer.py
# Domain: example.com
```
Test amaÃ§lÄ± resmi site.

### 5. **Python.org** âœ…
```bash
python sitemap_analyzer.py
# Domain: python.org
```
Python resmi sitesi, scraping'e izin veriyor.

---

## ğŸ“¦ KURULUM

### Gerekli KÃ¼tÃ¼phaneler:
```bash
pip install requests beautifulsoup4
```

### XML Parser Kurulumu (Windows):
```bash
pip install lxml
```

---

## ğŸš€ KULLANIM

### Basit KullanÄ±m:
```bash
python sitemap_analyzer.py
```

Sonra sorduÄŸunda domain yazÄ±n:
```
[?] Domain gir (Ã¶rn: example.com): wikipedia.org
```

### Ã‡Ä±ktÄ±:
```
================================================================================
[!] Ã–NEMLÄ° URL'LER (BUG BOUNTY)
================================================================================
[+] https://wikipedia.org/wiki/Admin -> Anahtar: admin

[*] DÄ°ÄER URL'LER
================================================================================
[-] https://wikipedia.org/wiki/Main_Page
[-] https://wikipedia.org/wiki/About
...

[+] SonuÃ§lar kaydedildi: wikipedia.org_sitemap_analysis.csv
```

---

## ğŸ“Š Ã‡IKTI DOSYASI

Analiz bitince **CSV dosyasÄ±** oluÅŸturulur:

**Dosya adÄ±:** `domain_sitemap_analysis.csv`

**Ä°Ã§eriÄŸi:**
| URL | Son GÃ¼ncelleme | GÃ¼ncelleme SÄ±klÄ±ÄŸÄ± | Ã–ncelik | TÃ¼r | Bulunan Kelime |
|-----|----------------|--------------------|---------|-----|----------------|
| https://example.com/admin | 2024-01-15 | weekly | 0.8 | Ã–NEMLÄ° | admin |
| https://example.com/blog | 2024-01-10 | daily | 0.5 | NORMAL | - |

---

## ğŸ” ARA KELIMELER

AracÄ±, bu kelimeleri bulunca URL'yi **Ã–NEMLÄ°** olarak iÅŸaretler:

```
admin, api, login, private, config, settings,
user, password, auth, backup, database, db,
secret, key, token, internal, panel, dashboard,
debug, test, staging, dev, development, console
```

Kendi kelimelerinizi eklemek iÃ§in `IMPORTANT_KEYWORDS` listesini dÃ¼zenleyin.

---

## ğŸ’¡ BUG BOUNTY ve CTF Ä°Ã§in Ä°PUÃ‡LARI

1. **Ã–nemli URL'leri kontrol edin** - `/admin`, `/api` vb. bulduÄŸunuzda onlarÄ± inceyin
2. **Son gÃ¼ncelleme tarihleri** - Yeni gÃ¼ncellenen sayfalar genelde etkin sunuculardÄ±r
3. **Robots.txt'i de kontrol edin** - AynÄ± domaine `/robots.txt` ekleyerek bakÄ±n
4. **Sitemap indeks** - `sitemap_index.xml` varsa, daha fazla sitemap olabilir

---

## â“ SORDUNDA HATALAR

### Hata: "sitemap bulunamadÄ±"
- Site sitemap.xml kullanmÄ±yor olabilir
- Domain doÄŸru yazÄ±lmÄ±ÅŸ mÄ± kontrol edin
- `https://` eklemeyin, sadece `example.com` yazÄ±n

### Hata: "BaÄŸlantÄ± hatasÄ±"
- Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin
- Firewall'a baÄŸlÄ± olabilir
- VPN kullanÄ±yorsanÄ±z kapatÄ±p deneyin

### Hata: "Parse hatasÄ±"
- Sitemap yapÄ±sÄ± standart deÄŸil olabilir
- Bir baÅŸka site deneyin

---

## ğŸ¯ HEDEF KURMAK (CTF Ä°Ã§in)

Ekibinizle birlikte ÅŸu hedefleri koyun:

1. âœ… Ä°lk 3 yasal sitede Ã§alÄ±ÅŸtÄ±rma
2. âœ… CSV Ã§Ä±ktÄ±sÄ±nÄ± analiz etme
3. âœ… Ã–nemli URL'leri manuel inceleme
4. âœ… Kendi robots.txt analiz aracÄ± yazma
5. âœ… Sitemap indeks analizi ekleme

---

## ğŸ“š KAYNAKLAR

- [Robots.txt Rehberi](https://www.robotstxt.org/)
- [Sitemap ProtokolÃ¼](https://www.sitemaps.org/)
- [Web Scraping Etikleri](https://en.wikipedia.org/wiki/Web_scraping)
- [OWASP - Recon](https://owasp.org/www-project-web-security-testing-guide/)

---

## ğŸ‘¥ EKIP Ã‡ALIÅMASI

13 kiÅŸilik takÄ±m olarak:

1. **Grup 1:** Wikipedia Ã¼zerinde pratik (3 kiÅŸi)
2. **Grup 2:** Quotes.toscrape Ã¼zerinde pratik (3 kiÅŸi)
3. **Grup 3:** SonuÃ§larÄ± analiz etme (4 kiÅŸi)
4. **Grup 4:** AracÄ± geliÅŸtirme ve iyileÅŸtirme (3 kiÅŸi)

Sonra bulgularÄ±nÄ±zÄ± paylaÅŸÄ±n!

---

## ğŸ“ NOTLAR

- Bu araÃ§ eÄŸitim amaÃ§lÄ± yapÄ±lmÄ±ÅŸtÄ±r
- **Yasal sorumluluk tamamen sizin Ã¼zerinizedir**
- KurallarÄ± ihlal ederseniz yasal sonuÃ§lar olabilir
- Bug bounty yapÄ±yorsanÄ±z, **program kurallarÄ±nÄ± okuyun**
- ÅÃ¼phe varsa, **sitede Ã§alÄ±ÅŸmadan Ã¶nce izin alÄ±n**

---

## ğŸ”§ GELÄ°ÅTÄ°RME FÄ°KÄ°RLERÄ°

AracÄ± geliÅŸtirmek iÃ§in yapabilecekleriniz:

- [ ] Sitemap indeks analizi (sitemap_index.xml)
- [ ] Robots.txt analizi
- [ ] HÄ±z testi (response time)
- [ ] Dead link kontrolÃ¼
- [ ] Grafik gÃ¶sterim (HTML raporu)
- [ ] Paralel indirileme (daha hÄ±zlÄ±)
- [ ] VeritabanÄ± kaydÄ±
- [ ] Web arayÃ¼zÃ¼ (Flask/Django)

---

**BaÅŸarÄ±lar! ğŸš€**

*Yazarlar: Siber GÃ¼venlik Ã–ÄŸrencileri - 9. SÄ±nÄ±f*